# -*- coding: utf-8 -*-
"""lab8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k2YgFhi0OTA60e5ktSFnYjhl5AUE0NGx
"""

# importing necessary libraries
import pandas as pd
import numpy as np

"""Removing Null values / Handling Missing data"""
# Please change the filepath if it shows file not found, 
# used IDE: Spyder, the code and dataset are kept in the same directory
mushEd = pd.read_csv('/content/sample_data/mushroom edibility classification dataset.csv') 
print(mushEd.head(3))
print(mushEd.shape)
print(mushEd.isnull().sum())
from sklearn.impute import SimpleImputer

impute = SimpleImputer(missing_values=np.nan, strategy='mean')
impute.fit(mushEd[['cap-shape']])
impute.fit(mushEd[['cap-color']])

mushEd['cap-shape'] = impute.transform(mushEd[['cap-shape']])
mushEd['cap-color'] = impute.transform(mushEd[['cap-color']])

mushEd_df = pd.DataFrame(mushEd, columns=mushEd.keys())
mushEd_corr = mushEd_df.corr()
print(mushEd_corr)
import seaborn as sns
sns.heatmap(mushEd_corr, cmap='YlGnBu')

"""dropping columns"""
print(mushEd['veil-type'].unique())
print(mushEd['veil-color'].unique())
print(mushEd['ring-number'].unique())
mushEd = mushEd.drop(['Unnamed: 0','veil-type','veil-color','ring-number'], axis = 1)
print(mushEd.shape)

'''Visualizing current Correlation between labels after dropping'''
mushEd_df = pd.DataFrame(mushEd, columns=mushEd.keys())
mushEd_corr = mushEd_df.corr()
print(mushEd_corr)
sns.heatmap(mushEd_corr, cmap='YlGnBu')

'''Encoding categorical features'''
from sklearn.preprocessing import LabelEncoder

# Set up the LabelEncoder object
enc = LabelEncoder()

# Apply the binary encoding to the "bruises" column
print(mushEd['bruises'].unique())
mushEd['bruises_enc'] = enc.fit_transform(mushEd['bruises'])
mushEd_df = pd.DataFrame(mushEd, columns=mushEd.keys())

# Compare the two columns
print(mushEd[['bruises', 'bruises_enc']].head())

'''Visualizing current Correlation between labels after feature encoding'''
mushEd_corr = mushEd_df.corr()
print(mushEd_corr)
sns.heatmap(mushEd_corr, cmap='YlGnBu')
mushEd_df = mushEd.drop(['bruises'], axis = 1)

'''Splitting dataset in 8:2 ratio for scaling'''
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(mushEd_df.iloc[:,1:],  mushEd_df['class'], test_size=0.2, random_state=42,  stratify = mushEd_df['class'])
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

'''Calculating percentage per target label'''
n_edible= np.sum(y_train=='edible')
n_poisonous= np.sum(y_train=='poisonous')
total= n_edible + n_poisonous
print("No. of poisonous mushrooms is",n_poisonous)
print("No. of edible mushrooms is",n_edible)
print("% of posionous mushrooms is",(n_poisonous/total)*100)
print("% of edible mushrooms is",(n_edible/total)*100)

''' Feature scaling using Standard Scaler '''
# preprocessing using zero mean and unit variance scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

'''Classification using Support Vector Machine'''

import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
svc = SVC(kernel="linear")
svc.fit(X_train, y_train)

print("Training accuracy of the model is {:.2f}".format(svc.score(X_train, y_train)))
print("Testing accuracy of the model is {:.2f}".format(svc.score(X_test, y_test)))

svcPredictions = svc.predict(X_test)
print(svcPredictions)
svcPredictions = svc.score(X_test, y_test)


from sklearn.metrics import confusion_matrix
mat=confusion_matrix(predictions, y_test)
print(mat)

from seaborn import heatmap
heatmap(mat , cmap="icefire", xticklabels=['edible' ,'poisonous' ], yticklabels=['edible' ,'poisonous'], annot=True)

'''Classification using Random Forest Classifier'''

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=50)
rfc.fit(X_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(rfc.score(X_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(rfc.score(X_test, y_test)))


rnfPredictions = rfc.predict(X_test)
print(rnfPredictions)
rnfPredictions = rfc.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
mat=confusion_matrix(predictions, y_test)
print(mat)

from seaborn import heatmap
heatmap(mat , cmap="icefire", xticklabels=['edible' ,'poisonous'], yticklabels=['edible' ,'poisonous'], annot=True)

'''Classification using Neural Network / Multi-Layer Perceptron Classifier'''

from sklearn.neural_network import MLPClassifier
nnc=MLPClassifier(hidden_layer_sizes=(7), activation="relu", max_iter=10000)
nnc.fit(X_train, y_train)

print("The Training accuracy of the model is {:.2f}".format(nnc.score(X_train, y_train)))
print("The Testing accuracy of the model is {:.2f}".format(nnc.score(X_test, y_test)))

nnPredictions = nnc.predict(X_test)
print(nnPredictions)
nnPredictions = nnc.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
mat=confusion_matrix(predictions, y_test)
print(mat)

from seaborn import heatmap
heatmap(mat , cmap="icefire", xticklabels=['edible' ,'poisonous' ], yticklabels=['edible' ,'poisonous'], annot=True)

'''Accuracy before PCA'''

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=4)
knn.fit(X_train, y_train)

# Performance of the KNN model when no dimensions are reduced
print("Before PCA\nTraining accuracy is {:.2f}".format(knn.score(X_train, y_train)) )
print("Testing accuracy is {:.2f} ".format(knn.score(X_test, y_test)) )

''' Applying PCA '''
from sklearn.preprocessing import StandardScaler
scaler= StandardScaler()

from sklearn.preprocessing import LabelEncoder
enc = LabelEncoder()
mushEd_df = mushEd.drop(['bruises'], axis = 1)
mushEd_df['class'] = enc.fit_transform(mushEd_df['class'])

print(mushEd_df['class'])
from sklearn.decomposition import PCA 
pca = PCA(n_components=8)

principal_components= pca.fit_transform(mushEd_df)
print(principal_components)
pca.explained_variance_ratio_

sum(pca.explained_variance_ratio_)
principal_df = pd.DataFrame(data=principal_components)
principal_df.head()
print(mushEd_df['class'])
main_df=pd.concat([principal_df, mushEd_df[['class']]], axis=1)
main_df.head()

Xp_train,Xp_test,yp_train,yp_test= train_test_split(principal_df,mushEd_df['class'],test_size=0.2, random_state=75)
print(Xp_train.shape)
print(Xp_test.shape)

svc.fit(Xp_train, yp_train)

print("Training accuracy of the model is {:.2f}".format(svc.score(Xp_train, yp_train)))
print("Testing accuracy of the model is {:.2f}".format(svc.score(Xp_test, yp_test)))
svcPredictions2 = svc.score(Xp_test, yp_test)

nnc.fit(Xp_train, yp_train)

print("The Training accuracy of the model is {:.2f}".format(nnc.score(Xp_train, yp_train)))
print("The Testing accuracy of the model is {:.2f}".format(nnc.score(Xp_test, yp_test)))
nnPredictions2 = nnc.score(Xp_test, yp_test)

rfc.fit(Xp_train, yp_train)

print("The Training accuracy of the model is {:.2f}".format(rfc.score(Xp_train, yp_train)))
print("The Testing accuracy of the model is {:.2f}".format(rfc.score(Xp_test, yp_test)))

rnfPredictions2 = rfc.score(Xp_test, yp_test)

'''Accuracy comparison'''
               
x_axis = ["SVC(Pre-PCA)","SVC(Post-PCA)","NN(Pre-PCA)", "NN(Post-PCA)","RNF(Pre-PCA)","RNF(Post-PCA)"]
y_axis = [svcPredictions*100,svcPredictions2*100,nnPredictions*100,nnPredictions2*100,rnfPredictions*100,rnfPredictions2*100]
frame= pd.DataFrame({'Classifier Method':x_axis,'Accuracy Score': y_axis})
sns.set_theme(style="whitegrid")
plt.figure(figsize=(20,10))
plt.title("Accuracy comparison of Pre-PCA and Post-PCA")

ax = sns.barplot(x="Classifier Method", y="Accuracy Score", data=frame, palette="viridis")